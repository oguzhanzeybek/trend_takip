import os
import json
import re
from datetime import datetime, timedelta
from typing import Optional, List, Dict, Any, Tuple, Union
from dotenv import load_dotenv

from supabase import create_client, Client
from openai import OpenAI

load_dotenv()

# ---------------------------------------------------------------------------
# AYARLAR VE BAÄLANTILAR
# ---------------------------------------------------------------------------

SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")
OPENROUTER_BASE_URL = "https://openrouter.ai/api/v1"
MODEL_NAME = "openai/gpt-4o-mini" 

supabase: Optional[Client] = None
ai_client: Optional[OpenAI] = None

# --- HAFIZA YÃ–NETÄ°MÄ° ---
conversation_history = []       # Sohbet metinlerini tutar
last_successful_data = []       # Son bulunan verileri tutar (BaÄŸlam hafÄ±zasÄ±)
last_date_info = ""             # Son kullanÄ±lan tarih bilgisini tutar

if SUPABASE_URL and SUPABASE_KEY:
    try:
        supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
        print("âœ… Supabase BaÄŸlantÄ±sÄ±: AKTÄ°F")
    except Exception as e:
        print(f"âŒ Supabase HatasÄ±: {e}")

if OPENROUTER_API_KEY:
    try:
        ai_client = OpenAI(api_key=OPENROUTER_API_KEY, base_url=OPENROUTER_BASE_URL)
        print(f"âœ… AI BaÄŸlantÄ±sÄ±: AKTÄ°F ({MODEL_NAME})")
    except Exception as e:
        print(f"âŒ AI HatasÄ±: {e}")

# ---------------------------------------------------------------------------
# YARDIMCI FONKSÄ°YONLAR (STEMMING & PARSING)
# ---------------------------------------------------------------------------

def simple_turkish_stemmer(word: str) -> str:
    """
    GeliÅŸtirilmiÅŸ TÃ¼rkÃ§e kÃ¶k bulucu v4 (Test odaklÄ± hassas ayar).
    """
    word = word.lower().strip()
    
    # Ã‡ok kÄ±sa kelimelere dokunma (ev, at, su)
    if len(word) < 3:
        return word

    # 1. Ã‡oÄŸul Ekleri (-lar, -ler)
    # Kalan kÄ±sÄ±m en az 3 harf olmalÄ± (kedi-ler -> kedi)
    if word.endswith(("lar", "ler")):
        if len(word[:-3]) >= 3:
            word = word[:-3]

    # 2. Hal Ekleri (-dan, -den, -tan, -ten, -da, -de, -ta, -te)
    # Ev-de -> Ev (Kalan 2 harf olabilir)
    if len(word) > 4 and word.endswith(("dan", "den", "tan", "ten")):
        word = word[:-3]
    
    if len(word) > 3 and word.endswith(("da", "de", "ta", "te")):
        word = word[:-2]

    # 3. Ä°yelik ve Tamlama Ekleri (-nÄ±n, -nin, -nun, -nÃ¼n, -sÄ±, -si, -su, -sÃ¼)
    if len(word) > 4:
        if word.endswith(("nÄ±n", "nin", "nun", "nÃ¼n")):
            word = word[:-3]
        elif word.endswith(("sÄ±", "si", "su", "sÃ¼")):
            word = word[:-2]

    # 4. Tek harfli ekler (-Ä±, -i, -u, -Ã¼, -n, -m)
    # "KitabÄ±n" -> "KitabÄ±" -> "Kitap" dÃ¶nÃ¼ÅŸÃ¼mÃ¼ iÃ§in dÃ¶ngÃ¼
    for _ in range(2): 
        # -Ä±, -i, -u, -Ã¼ eklerini atarken kelime en az 5 harfli olmalÄ± ki "Kedi" -> "Ked" olmasÄ±n.
        if len(word) > 4: 
            if word.endswith(("Ä±", "i", "u", "Ã¼")):
                word = word[:-1]
            elif word.endswith("n") and not word.endswith("sun"): 
                word = word[:-1]
        
        # -m eki Ã§ok riskli (Kalem -> Kale hatasÄ±). Sadece 6 harf ve Ã¼zeri kelimelerde at.
        # (Babam -> Baba olur, ama Kalem -> Kalem kalÄ±r)
        if len(word) > 5:
            if word.endswith("m") and not word.endswith("yim") and not word.endswith("ÄŸim"):
                word = word[:-1]
    
    # Sert sessiz yumuÅŸamasÄ± dÃ¼zeltme (kitab -> kitap)
    # Sadece belli uzunluktaki kelimelerde yap
    if word.endswith("b") and len(word) > 3: 
        word = word[:-1] + "p"
    if word.endswith("c") and len(word) > 3:
        word = word[:-1] + "Ã§"
    if word.endswith("d") and len(word) > 3:
        word = word[:-1] + "t"

    return word

def safe_json_parse(content: Any) -> Any:
    if isinstance(content, dict): return content
    if isinstance(content, str):
        try:
            return json.loads(content)
        except:
            return {}
    return {}

def extract_date_range_from_query(text: str) -> Tuple[datetime, datetime]:
    """Sorgudan tarih ARALIÄI Ã§eker."""
    text = text.lower()
    now = datetime.now()
    
    # 1. "Son X GÃ¼n" MantÄ±ÄŸÄ±
    match_days = re.search(r"son (\d+) gÃ¼n", text)
    if match_days:
        days = int(match_days.group(1))
        start_date = now - timedelta(days=days)
        return start_date, now

    if "son hafta" in text or "bir hafta" in text:
        return now - timedelta(days=7), now

    # 2. GÃ¶reli Tarihler (Ã–NCELÄ°K SIRASI DÃœZELTÄ°LDÄ°)
    # Ã–nce "dÃ¼n ve bugÃ¼n" kontrolÃ¼ yapÄ±lmalÄ±
    if "dÃ¼n" in text and "bugÃ¼n" in text:
        start = now - timedelta(days=1)
        return start, now 

    if "dÃ¼n" in text:
        start = now - timedelta(days=1)
        return start, start 
    
    if "bugÃ¼n" in text:
        return now, now
    
    # 3. Ay Ä°simli Tarihler
    months = {
        "ocak": 1, "ÅŸubat": 2, "mart": 3, "nisan": 4, "mayÄ±s": 5, "haziran": 6,
        "temmuz": 7, "aÄŸustos": 8, "eylÃ¼l": 9, "ekim": 10, "kasÄ±m": 11, "aralÄ±k": 12
    }
    for month_name, month_num in months.items():
        if month_name in text:
            match = re.search(r"(\d+)\s+" + month_name, text)
            if match:
                day = int(match.group(1))
                try:
                    dt = datetime(now.year, month_num, day)
                    if dt > now + timedelta(days=1):
                        dt = datetime(now.year - 1, month_num, day)
                    return dt, dt
                except:
                    pass
    
    return now, now

def clean_search_term(text: Union[str, List[str]]) -> str:
    """
    Sorgudan gereksiz dolgu kelimelerini temizler.
    HATA DÃœZELTME: Gelen veri liste ise stringe Ã§evirir (Test 49 HatasÄ± Ã‡Ã¶zÃ¼mÃ¼).
    """
    # EÄŸer liste gelirse stringe Ã§evir
    if isinstance(text, list):
        text = " ".join(text)
        
    text = str(text).lower() # Her ihtimale karÅŸÄ± stringe zorla
    
    months = ["ocak", "ÅŸubat", "mart", "nisan", "mayÄ±s", "haziran", "temmuz", "aÄŸustos", "eylÃ¼l", "ekim", "kasÄ±m", "aralÄ±k"]
    for m in months:
        text = re.sub(r"\d+\s+" + m, "", text)
        text = re.sub(r"\b" + m + r"\b", "", text) 

    text = re.sub(r"son \d+ gÃ¼n", "", text)
    text = text.replace("dÃ¼n", "").replace("bugÃ¼n", "")

    stopwords = [
        "neler", "oldu", "var", "mi", "mu", "hakkÄ±nda", "ile", "ilgili", "durum", "ne", 
        "tarihinde", "gÃ¼nÃ¼", "fiyatlarÄ±", "fiyatÄ±", "verileri", "getir", "gÃ¶ster", "ve", "veya", 
        "en", "ucuz", "pahalÄ±", "hangisi", "peki", "bunlarÄ±n", "ÅŸunlarÄ±n", "onlarÄ±n", "iÃ§inde", 
        "arasÄ±nda", "olan", "kadar", "daha", "Ã§ok", "az", "yÃ¼ksek", "dÃ¼ÅŸÃ¼k", "ÅŸu", "bu", "o",
        "Ã¶zellikleri", "tarafÄ±nda", "Ã¶ne", "Ã§Ä±kan", "baÅŸlÄ±klar", "konuÅŸuldu", "listele", "hepsini", "tÃ¼mÃ¼nÃ¼"
    ]
    for word in stopwords:
        text = re.sub(r'\b' + word + r'\b', '', text)
    
    return text.strip()

# ---------------------------------------------------------------------------
# VERÄ°TABANI Ä°ÅLEMLERÄ° (LÄ°MÄ°TSÄ°Z Ã‡EKÄ°M)
# ---------------------------------------------------------------------------

async def fetch_data_in_range(start_date: datetime, end_date: datetime) -> List[Dict]:
    """Limitsiz (Pagination) veri Ã§ekimi."""
    if not supabase: return []
    
    all_data = []
    chunk_size = 1000 
    offset = 0
    
    try:
        start_str = start_date.replace(hour=0, minute=0, second=0).isoformat()
        end_str = end_date.replace(hour=23, minute=59, second=59).isoformat()

        print(f"ğŸ“¡ Veri Ã‡ekiliyor (Limitsiz Mod): {start_str} -> {end_str}")

        while True:
            response = (
                supabase.table("processed_data")
                .select("*")
                .in_("data_type", ["Filtered", "Analyzed"]) 
                .filter("created_at", "gte", start_str)
                .filter("created_at", "lte", end_str)
                .order("created_at", desc=True)
                .range(offset, offset + chunk_size - 1)
                .execute()
            )
            
            batch = response.data if response.data else []
            if not batch: break
                
            all_data.extend(batch)
            print(f"   â†³ {len(batch)} satÄ±r Ã§ekildi (Toplam: {len(all_data)})")
            
            if len(batch) < chunk_size: break
            offset += chunk_size

        print(f"âœ… TOPLAM Ã‡EKÄ°LEN VERÄ° SAYISI: {len(all_data)}")
        return all_data
    except Exception as e:
        print(f"âŒ Veri Ã‡ekme HatasÄ±: {e}")
        return []

# ---------------------------------------------------------------------------
# AI NÄ°YET ANALÄ°ZÄ°
# ---------------------------------------------------------------------------

def get_search_intent_via_ai(user_prompt: str) -> dict:
    if not ai_client: return {"intent": "search", "value": user_prompt}

    # SOHBET MODU EKLENDÄ°
    system_prompt = """
    KullanÄ±cÄ± mesajÄ±nÄ± analiz et ve JSON dÃ¶ndÃ¼r.
    
    1. SOHBET (Chat): "Selam", "NasÄ±lsÄ±n", "Kimsin", "TeÅŸekkÃ¼rler", "Ne haber" -> {"intent": "chat", "value": "chat"}
    2. Sentiment: "Halk ne hissediyor?", "Duygu", "KaygÄ±" -> {"intent": "sentiment", "value": "sentiment"}
    3. Kategori: "Sosyal medya", "AlÄ±ÅŸveriÅŸ" -> {"intent": "category", "value": "social_media"} (veya online_shopping)
    4. Platform: "Trendyol", "Twitter" -> {"intent": "platform", "value": "trendyol"}
    5. Erken Trend: "Erken trend", "Yeni Ã§Ä±kan" -> {"intent": "early_trend", "value": "true"}
    6. Genel Arama: "iPhone", "BeÅŸiktaÅŸ", "Termos" -> {"intent": "search", "value": "aranan_kelime"}
    """
    try:
        completion = ai_client.chat.completions.create(
            model=MODEL_NAME, 
            messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}],
            temperature=0, max_tokens=60
        )
        clean_json = completion.choices[0].message.content.replace("```json", "").replace("```", "").strip()
        return json.loads(clean_json)
    except:
        return {"intent": "search", "value": user_prompt}

# ---------------------------------------------------------------------------
# AKILLI FÄ°LTRELEME
# ---------------------------------------------------------------------------

async def fetch_smart_filtered_data(user_query: str, intent_data: dict) -> Tuple[List[Dict], str]:
    if not supabase: return [], "VeritabanÄ± Yok"

    start_date, end_date = extract_date_range_from_query(user_query)
    
    if start_date.date() == end_date.date():
        date_info = start_date.strftime('%d %B %Y')
    else:
        date_info = f"{start_date.strftime('%d %B')} - {end_date.strftime('%d %B %Y')}"

    intent_type = intent_data.get("intent", "search")
    if intent_type == "chat": return [], date_info

    raw_value = intent_data.get("value", user_query)
    
    # HATA DÃœZELTME: raw_value burada liste gelse bile clean_search_term onu stringe Ã§evirir.
    cleaned_value = clean_search_term(raw_value) if intent_type == "search" else str(raw_value).lower().strip().replace("#", "")
    search_keywords = cleaned_value.split() if cleaned_value else []

    # HafÄ±za kontrolÃ¼ iÃ§in boÅŸ arama
    if intent_type == "search" and not search_keywords:
        if "aralÄ±k" in user_query.lower() or "dÃ¼n" in user_query.lower() or "bugÃ¼n" in user_query.lower() or "gÃ¼n" in user_query.lower():
             pass
        else:
             print("ğŸ’¡ Arama terimi bulunamadÄ± (Devam sorusu), hafÄ±za kullanÄ±lacak...")
             return [], date_info

    # TÃœM VERÄ°YÄ° Ã‡EK (Limitsiz)
    raw_rows = await fetch_data_in_range(start_date, end_date)
    if not raw_rows: return [], date_info

    print(f"ğŸ•µï¸ Filtreleme: Niyet='{intent_type}', Kelimeler={search_keywords}")
    
    # Sadece tarih sorulduysa tÃ¼mÃ¼nÃ¼ dÃ¶n
    if intent_type == "search" and not search_keywords:
        print("ğŸ’¡ Sadece tarih/zaman soruldu, tÃ¼m veriler analiz edilecek...")
        return raw_rows, date_info

    filtered_results = []

    for row in raw_rows:
        category = str(row.get('category', '')).lower()
        source_col = str(row.get('source', '')).lower()
        data_type = str(row.get('data_type', '')).lower()
        content = safe_json_parse(row.get('content'))
        
        json_kaynak = str(content.get('kaynak', '')).lower()
        json_not = str(content.get('not', '')).lower()
        json_full_text = str(content).lower()

        match = False

        if intent_type == "sentiment":
            if "analyzed" in data_type or "sentiment" in category or "kaygÄ±" in json_full_text:
                match = True

        elif intent_type == "category":
            if cleaned_value in category or cleaned_value in source_col:
                match = True

        elif intent_type == "platform":
            if cleaned_value in source_col or cleaned_value in json_kaynak or cleaned_value in category:
                match = True
            if cleaned_value == "trendyol" and "online_shopping" in source_col:
                match = True 

        elif intent_type == "early_trend":
            if "erkentrend" in json_not or "erken" in json_full_text:
                match = True

        else:
            found_keyword = False
            for word in search_keywords:
                if len(word) > 2:
                    stemmed_word = simple_turkish_stemmer(word)
                    if (word in json_full_text or stemmed_word in json_full_text or 
                        word in source_col or 
                        word in category or 
                        word in json_not or
                        word in json_kaynak):
                        found_keyword = True
                        break
            if found_keyword:
                match = True

        if match:
            filtered_results.append(row)

    print(f"âœ… EÅŸleÅŸen KayÄ±t SayÄ±sÄ±: {len(filtered_results)}")
    return filtered_results, date_info

# ---------------------------------------------------------------------------
# CHAT MOTORU
# ---------------------------------------------------------------------------

async def chat_with_ai(user_message: str) -> str:
    global conversation_history, last_successful_data, last_date_info
    
    if not ai_client: return "âš ï¸ AI sistemi baÄŸlÄ± deÄŸil."

    intent_data = get_search_intent_via_ai(user_message)
    intent_type = intent_data.get("intent", "search")

    # 1. SOHBET MODU
    if intent_type == "chat":
        chat_system_prompt = """
        Sen TrendAI, yardÄ±mcÄ± ve arkadaÅŸ canlÄ±sÄ± bir veri asistanÄ±sÄ±n.
        
        GÃ–REVÄ°N:
        1. KullanÄ±cÄ±nÄ±n selamÄ±na veya sohbetine nazikÃ§e ve profesyonelce karÅŸÄ±lÄ±k ver.
        2. Kendini tanÄ±t: "Ben TrendAI, sosyal medya, e-ticaret ve trendleri analiz eden yapay zeka asistanÄ±yÄ±m."
        3. KullanÄ±cÄ±ya ne aramak istediÄŸini sor.
        4. KÄ±sa, samimi ve Markdown formatÄ±nda (bold, italik, liste) dÃ¼zenli cevaplar ver.
        """
        
        messages = [{"role": "system", "content": chat_system_prompt}]
        messages.extend(conversation_history[-4:])
        messages.append({"role": "user", "content": user_message})
        
        try:
            response = ai_client.chat.completions.create(model=MODEL_NAME, messages=messages, temperature=0.7)
            ai_response = response.choices[0].message.content
            conversation_history.append({"role": "user", "content": user_message})
            conversation_history.append({"role": "assistant", "content": ai_response})
            return ai_response
        except:
            return "Merhaba! Åu an sohbet sistemimde bir yoÄŸunluk var, ama verileri sorgulayabilirim."

    # 2. VERÄ° Ã‡EKME
    db_data, date_info = await fetch_smart_filtered_data(user_message, intent_data)
    
    # HafÄ±za KontrolÃ¼
    used_cached_data = False
    if not db_data and last_successful_data:
        print("ğŸ”„ HafÄ±zadaki veri kullanÄ±lÄ±yor...")
        db_data = last_successful_data
        date_info = last_date_info
        used_cached_data = True
    
    count_found = len(db_data)

    if not db_data:
        response_msg = f"ğŸ” **{date_info}** tarih aralÄ±ÄŸÄ±nda uygun veri bulamadÄ±m."
        conversation_history.append({"role": "user", "content": user_message})
        conversation_history.append({"role": "assistant", "content": response_msg})
        return response_msg

    if not used_cached_data:
        last_successful_data = db_data
        last_date_info = date_info

    # 3. Context HazÄ±rlama
    clean_context = []
    # Token limiti iÃ§in en gÃ¼ncel 200 veriyi analiz et
    for row in db_data[:200]: 
        content = safe_json_parse(row.get('content'))
        src = row.get('source', '').replace('.csv', '').replace('filtered_', '')
        if isinstance(content, dict) and content.get('kaynak'):
             src = content.get('kaynak')
        clean_context.append({"Platform": src, "Veri": content})

    context_str = json.dumps(clean_context, ensure_ascii=False)

    # 4. Veri Analiz Prompt'u (FORMAT GÃœNCELLEMESÄ°)
    # 4. Veri Analiz Prompt'u (TABLO FORMATI GÃœNCELLEMESÄ°)
    system_prompt = f"""
    Sen TrendAI, verilerin derinliklerini gÃ¶ren, **Ãœst DÃ¼zey Pazar AraÅŸtÄ±rmacÄ±sÄ± ve Trend Stratejistisin.** ğŸ§
    KullanÄ±cÄ±ya ham veri deÄŸil, **iÅŸlenebilir iÃ§gÃ¶rÃ¼ler** ve **stratejik analizler** sunmalÄ±sÄ±n.
    
    **ZORUNLU GÄ°RÄ°Å FORMATI:**
    
    > ğŸ“‹ **Sorgu Raporu**
    > * **Tarih:** {date_info}
    
    
    
    **GÃ–RSEL VE ANALÄ°Z KURALLARI (KESÄ°N UY):**
    
    1. **BAÅLIK:** `## ğŸš€ {date_info} Stratejik Trend Raporu`
       AltÄ±na italik bir Ã¶zet: *"Toplam **{count_found}** veri noktasÄ± tarandÄ± ve piyasa hareketleri analiz edildi."*

    2. **PLATFORM GRUPLAMASI:** Verileri platformlarÄ±na gÃ¶re ayÄ±r (Ã–rn: `### ğŸ›ï¸ Trendyol Analizi`).

    3. **HÄ°YERARÅÄ°K LÄ°STE FORMATI (ZORUNLU):**
       Her Ã¼rÃ¼nÃ¼ bir ana madde, Ã¶zelliklerini ise girintili (indented) alt maddeler olarak yaz. 
       Veri iÃ§indeki etiketlerden (hashtag) yola Ã§Ä±karak kÄ±sa bir "Uzman Yorumu" ekle.
       
       **Åu formatÄ± birebir uygula:**
       
       - ğŸ“¦ **ÃœrÃ¼n:[ÃœrÃ¼n AdÄ±]**
         - ğŸ’° **Fiyat:** [Fiyat] 
         - ğŸ“ˆ **Trend Skoru:** [Skor] / 100
         - ğŸ·ï¸ **Etiketler:** [Not/Hashtagler]
         - ğŸ§  **Uzman Yorumu:** [Buraya Ã¼rÃ¼nÃ¼n neden trend olduÄŸuna dair 1 cÃ¼mlelik keskin bir analiz yaz.] [.Yeni Ã¼rÃ¼ne geÃ§meden Ã¶nce 1 boÅŸ satÄ±r bÄ±rak. ve  bir satÄ±r boyunca yatay Ã§izgi koy ve tekrar bir satÄ±r boÅŸluk bÄ±rak]
         

    4. cevabÄ±n okunabÄ±lÄ±r olsun.
    

    5. **TON:** Profesyonel, kendinden emin ama anlaÅŸÄ±lÄ±r. Teknik terim (JSON vb.) yasak.
    
    6. **KAPANIÅ:** "Hangi Ã¼rÃ¼nÃ¼n pazar analizini derinleÅŸtirelim?" gibi stratejik bir soru sor.
    """

    messages = [{"role": "system", "content": system_prompt}]
    messages.extend(conversation_history[-4:]) 
    messages.append({"role": "user", "content": f"VERÄ° SETÄ°:\n{context_str}\n\nSORU: {user_message}"})

    try:
        response = ai_client.chat.completions.create(model=MODEL_NAME, messages=messages, temperature=0.7)
        ai_response = response.choices[0].message.content
        conversation_history.append({"role": "user", "content": user_message})
        conversation_history.append({"role": "assistant", "content": ai_response})
        return ai_response
    except Exception as e:
        return f"AI HatasÄ±: {e}"

async def process_user_input(text: str) -> str:
    return await chat_with_ai(text)

async def fetch_large_recent_dataset(limit: int = 50): return []
async def save_trend(content: Any): return None
async def get_filtered_raw_data(categories, limit): return []
async def get_trends(limit=20): return []
async def get_products(): return []
async def get_stats(): return []
async def get_latest_trend_data(): return None