import os
import json
import re
from datetime import datetime, timedelta
from typing import Optional, List, Dict, Any, Tuple
from dotenv import load_dotenv

from supabase import create_client, Client
from openai import OpenAI

load_dotenv()

# ---------------------------------------------------------------------------
# AYARLAR VE BAÄLANTILAR
# ---------------------------------------------------------------------------

SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")
OPENROUTER_BASE_URL = "https://openrouter.ai/api/v1"
MODEL_NAME = "openai/gpt-4o-mini" 

supabase: Optional[Client] = None
ai_client: Optional[OpenAI] = None

# --- HAFIZA YÃ–NETÄ°MÄ° ---
conversation_history = []       # Sohbet metinlerini tutar
last_successful_data = []       # Son bulunan verileri tutar (BaÄŸlam hafÄ±zasÄ±)
last_date_info = ""             # Son kullanÄ±lan tarih bilgisini tutar

if SUPABASE_URL and SUPABASE_KEY:
    try:
        supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
        print("âœ… Supabase BaÄŸlantÄ±sÄ±: AKTÄ°F")
    except Exception as e:
        print(f"âŒ Supabase HatasÄ±: {e}")

if OPENROUTER_API_KEY:
    try:
        ai_client = OpenAI(api_key=OPENROUTER_API_KEY, base_url=OPENROUTER_BASE_URL)
        print(f"âœ… AI BaÄŸlantÄ±sÄ±: AKTÄ°F ({MODEL_NAME})")
    except Exception as e:
        print(f"âŒ AI HatasÄ±: {e}")

# ---------------------------------------------------------------------------
# YARDIMCI FONKSÄ°YONLAR (STEMMING & PARSING)
# ---------------------------------------------------------------------------

def simple_turkish_stemmer(word: str) -> str:
    """TÃ¼rkÃ§e kelime kÃ¶kÃ¼ bulucu."""
    word = word.lower().strip()
    suffixes = [
        "lar", "ler", "nÄ±n", "nin", "nun", "nÃ¼n", "dan", "den", "tan", "ten",
        "da", "de", "ta", "te", "Ä±", "i", "u", "Ã¼", "a", "e", "n", "m", "sÄ±", "si", "su", "sÃ¼"
    ]
    if len(word) < 4: return word
    for suffix in suffixes:
        if word.endswith(suffix):
            if len(word) - len(suffix) >= 3:
                return word[:-len(suffix)]
    return word

def safe_json_parse(content: Any) -> Any:
    if isinstance(content, dict): return content
    if isinstance(content, str):
        try: return json.loads(content)
        except: return {}
    return {}

def extract_date_range_from_query(text: str) -> Tuple[datetime, datetime]:
    """Sorgudan tarih ARALIÄI Ã§eker."""
    text = text.lower()
    now = datetime.now()
    
    # 1. "Son X GÃ¼n" MantÄ±ÄŸÄ±
    match_days = re.search(r"son (\d+) gÃ¼n", text)
    if match_days:
        days = int(match_days.group(1))
        start_date = now - timedelta(days=days)
        return start_date, now

    if "son hafta" in text or "bir hafta" in text:
        return now - timedelta(days=7), now

    # 2. GÃ¶reli Tarihler
    if "dÃ¼n" in text and "bugÃ¼n" in text:
        start = now - timedelta(days=1)
        return start, now 

    if "dÃ¼n" in text:
        start = now - timedelta(days=1)
        return start, start 
    
    if "bugÃ¼n" in text:
        return now, now
    
    # 3. Ay Ä°simli Tarihler
    months = {
        "ocak": 1, "ÅŸubat": 2, "mart": 3, "nisan": 4, "mayÄ±s": 5, "haziran": 6,
        "temmuz": 7, "aÄŸustos": 8, "eylÃ¼l": 9, "ekim": 10, "kasÄ±m": 11, "aralÄ±k": 12
    }
    for month_name, month_num in months.items():
        if month_name in text:
            match = re.search(r"(\d+)\s+" + month_name, text)
            if match:
                day = int(match.group(1))
                try:
                    dt = datetime(now.year, month_num, day)
                    if dt > now + timedelta(days=1):
                        dt = datetime(now.year - 1, month_num, day)
                    return dt, dt
                except:
                    pass
    
    return now, now

def clean_search_term(text: str) -> str:
    text = text.lower()
    months = ["ocak", "ÅŸubat", "mart", "nisan", "mayÄ±s", "haziran", "temmuz", "aÄŸustos", "eylÃ¼l", "ekim", "kasÄ±m", "aralÄ±k"]
    for m in months:
        text = re.sub(r"\d+\s+" + m, "", text)
    text = re.sub(r"son \d+ gÃ¼n", "", text)
    text = text.replace("dÃ¼n", "").replace("bugÃ¼n", "")

    stopwords = ["neler", "oldu", "var", "mi", "mu", "hakkÄ±nda", "ile", "ilgili", "durum", "ne", 
                 "tarihinde", "gÃ¼nÃ¼", "fiyatlarÄ±", "fiyatÄ±", "verileri", "getir", "gÃ¶ster", "ve", "veya", 
                 "en", "ucuz", "pahalÄ±", "hangisi", "peki", "bunlarÄ±n", "ÅŸunlarÄ±n", "onlarÄ±n", "iÃ§inde", 
                 "arasÄ±nda", "olan", "kadar", "daha", "Ã§ok", "az", "yÃ¼ksek", "dÃ¼ÅŸÃ¼k", "ÅŸu", "bu", "o",
                 "Ã¶zellikleri", "tarafÄ±nda", "Ã¶ne", "Ã§Ä±kan", "baÅŸlÄ±klar", "konuÅŸuldu", "listele"]
    for word in stopwords:
        text = text.replace(f" {word} ", " ").replace(f" {word}", "").replace(f"{word} ", "")
    
    return text.strip()

# ---------------------------------------------------------------------------
# VERÄ°TABANI Ä°ÅLEMLERÄ° (LÄ°MÄ°TSÄ°Z Ã‡EKÄ°M)
# ---------------------------------------------------------------------------

async def fetch_data_in_range(start_date: datetime, end_date: datetime) -> List[Dict]:
    if not supabase: return []
    try:
        start_str = start_date.replace(hour=0, minute=0, second=0).isoformat()
        end_str = end_date.replace(hour=23, minute=59, second=59).isoformat()

        print(f"ğŸ“¡ Veri Ã‡ekiliyor: {start_str} -> {end_str}")

        response = (
            supabase.table("processed_data")
            .select("*")
            .in_("data_type", ["Filtered", "Analyzed"]) 
            .filter("created_at", "gte", start_str)
            .filter("created_at", "lte", end_str)
            .order("created_at", desc=True)
            .limit(100000) 
            .execute()
        )
        data = response.data if response.data else []
        print(f"âœ… Ã‡ekilen Ham Veri SayÄ±sÄ±: {len(data)}")
        return data
    except Exception as e:
        print(f"âŒ Veri Ã‡ekme HatasÄ±: {e}")
        return []

# ---------------------------------------------------------------------------
# AI NÄ°YET ANALÄ°ZÄ° (GÃœNCELLENDÄ°: CHAT MODU EKLENDÄ°)
# ---------------------------------------------------------------------------

def get_search_intent_via_ai(user_prompt: str) -> dict:
    if not ai_client: return {"intent": "search", "value": user_prompt}

    # GÃœNCELLEME: "chat" niyeti eklendi
    system_prompt = """
    KullanÄ±cÄ± mesajÄ±nÄ± analiz et ve JSON dÃ¶ndÃ¼r.
    
    1. SOHBET (Chat): "Selam", "NasÄ±lsÄ±n", "Kimsin", "TeÅŸekkÃ¼rler", "Ne yapabilirsin?" -> {"intent": "chat", "value": "chat"}
    2. Sentiment: "Halk ne hissediyor?", "Duygu", "KaygÄ±" -> {"intent": "sentiment", "value": "sentiment"}
    3. Kategori: "Sosyal medya", "AlÄ±ÅŸveriÅŸ" -> {"intent": "category", "value": "social_media"} (veya online_shopping)
    4. Platform: "Trendyol", "Twitter" -> {"intent": "platform", "value": "trendyol"}
    5. Erken Trend: "Erken trend", "Yeni Ã§Ä±kan" -> {"intent": "early_trend", "value": "true"}
    6. Genel Arama: "iPhone", "BeÅŸiktaÅŸ", "Termos" -> {"intent": "search", "value": "aranan_kelime"}
    """
    try:
        completion = ai_client.chat.completions.create(
            model=MODEL_NAME, 
            messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}],
            temperature=0, max_tokens=60
        )
        clean_json = completion.choices[0].message.content.replace("```json", "").replace("```", "").strip()
        return json.loads(clean_json)
    except:
        return {"intent": "search", "value": user_prompt}

# ---------------------------------------------------------------------------
# AKILLI FÄ°LTRELEME (STEMMING + DEEP SEARCH)
# ---------------------------------------------------------------------------

async def fetch_smart_filtered_data(user_query: str, intent_data: dict) -> Tuple[List[Dict], str]:
    if not supabase: return [], "VeritabanÄ± Yok"

    start_date, end_date = extract_date_range_from_query(user_query)
    
    if start_date.date() == end_date.date():
        date_info = start_date.strftime('%d %B %Y')
    else:
        date_info = f"{start_date.strftime('%d %B')} - {end_date.strftime('%d %B %Y')}"

    intent_type = intent_data.get("intent", "search")
    
    # EÄER NÄ°YET SOHBET Ä°SE VERÄ° Ã‡EKMEYE GEREK YOK
    if intent_type == "chat":
        return [], date_info

    raw_value = intent_data.get("value", user_query).lower().strip().replace("#", "")
    
    cleaned_value = clean_search_term(raw_value) if intent_type == "search" else raw_value
    search_keywords = cleaned_value.split() if cleaned_value else []

    if intent_type == "search" and not search_keywords:
        if "aralÄ±k" in user_query.lower() or "dÃ¼n" in user_query.lower() or "bugÃ¼n" in user_query.lower() or "gÃ¼n" in user_query.lower():
             # Tarih var ama kelime yok, veriyi Ã§ekmeliyiz
             pass
        else:
             print("ğŸ’¡ Arama terimi bulunamadÄ± (Devam sorusu), hafÄ±za kullanÄ±lacak...")
             return [], date_info

    raw_rows = await fetch_data_in_range(start_date, end_date)
    if not raw_rows: return [], date_info

    print(f"ğŸ•µï¸ Filtreleme: Niyet='{intent_type}', Kelimeler={search_keywords}")
    
    # Sadece tarih sorulduysa tÃ¼mÃ¼nÃ¼ dÃ¶n
    if intent_type == "search" and not search_keywords:
        print("ğŸ’¡ Sadece tarih/zaman soruldu, tÃ¼m veriler Ã¶zetleniyor...")
        return raw_rows, date_info

    filtered_results = []

    for row in raw_rows:
        category = str(row.get('category', '')).lower()
        source_col = str(row.get('source', '')).lower()
        data_type = str(row.get('data_type', '')).lower()
        content = safe_json_parse(row.get('content'))
        
        json_kaynak = str(content.get('kaynak', '')).lower()
        json_not = str(content.get('not', '')).lower()
        json_full_text = str(content).lower()

        match = False

        if intent_type == "sentiment":
            if "analyzed" in data_type or "sentiment" in category or "kaygÄ±" in json_full_text:
                match = True

        elif intent_type == "category":
            if cleaned_value in category or cleaned_value in source_col:
                match = True

        elif intent_type == "platform":
            if cleaned_value in source_col or cleaned_value in json_kaynak or cleaned_value in category:
                match = True
            if cleaned_value == "trendyol" and "online_shopping" in source_col:
                match = True 

        elif intent_type == "early_trend":
            if "erkentrend" in json_not or "erken" in json_full_text:
                match = True

        else:
            found_keyword = False
            for word in search_keywords:
                if len(word) > 2:
                    stemmed_word = simple_turkish_stemmer(word)
                    if (word in json_full_text or stemmed_word in json_full_text or 
                        word in source_col or 
                        word in category or 
                        word in json_not or
                        word in json_kaynak):
                        found_keyword = True
                        break
            if found_keyword:
                match = True

        if match:
            filtered_results.append(row)

    print(f"âœ… EÅŸleÅŸen KayÄ±t SayÄ±sÄ±: {len(filtered_results)}")
    return filtered_results, date_info

# ---------------------------------------------------------------------------
# CHAT MOTORU (GELÄ°ÅMÄ°Å HAFIZA, SOHBET VE BAÄLAM)
# ---------------------------------------------------------------------------

async def chat_with_ai(user_message: str) -> str:
    global conversation_history, last_successful_data, last_date_info
    
    if not ai_client: return "âš ï¸ AI sistemi baÄŸlÄ± deÄŸil."

    # 1. Niyet Analizi
    intent_data = get_search_intent_via_ai(user_message)
    intent_type = intent_data.get("intent", "search")

    # --- SOHBET MODU (YENÄ° EKLENDÄ°) ---
    # EÄŸer niyet 'chat' ise veritabanÄ± iÅŸlemlerini atla ve direkt sohbet et
    if intent_type == "chat":
        chat_system_prompt = """
        Sen TrendAI, yardÄ±mcÄ± ve arkadaÅŸ canlÄ±sÄ± bir veri asistanÄ±sÄ±n.
        
        GÃ–REVÄ°N:
        1. KullanÄ±cÄ±nÄ±n selamÄ±na veya sohbetine nazikÃ§e karÅŸÄ±lÄ±k ver.
        2. Kendini tanÄ±t: "Ben TrendAI, sosyal medya, e-ticaret ve trendleri analiz eden yapay zeka asistanÄ±yÄ±m."
        3. KullanÄ±cÄ±ya ne aramak istediÄŸini sor (Ã–rn: "BugÃ¼n Trendyol'da neler olduÄŸunu merak ediyor musun?").
        4. KÄ±sa ve samimi cevaplar ver.
        """
        
        messages = [{"role": "system", "content": chat_system_prompt}]
        messages.extend(conversation_history[-4:])
        messages.append({"role": "user", "content": user_message})
        
        try:
            response = ai_client.chat.completions.create(model=MODEL_NAME, messages=messages, temperature=0.7)
            ai_response = response.choices[0].message.content
            conversation_history.append({"role": "user", "content": user_message})
            conversation_history.append({"role": "assistant", "content": ai_response})
            return ai_response
        except:
            return "Merhaba! Åu an sohbet sistemimde bir yoÄŸunluk var, ama verileri sorgulayabilirim."

    # 2. Veri Ã‡ekme (Sohbet deÄŸilse)
    db_data, date_info = await fetch_smart_filtered_data(user_message, intent_data)
    
    # --- BAÄLAM KONTROLÃœ ---
    used_cached_data = False
    
    # Yeni veri yoksa + HafÄ±za varsa -> HafÄ±zayÄ± kullan
    if not db_data and last_successful_data:
        print("ğŸ”„ Yeni arama boÅŸ dÃ¶ndÃ¼, Ã¶nceki BAÄLAM (HafÄ±za) kullanÄ±lÄ±yor...")
        db_data = last_successful_data
        date_info = last_date_info
        used_cached_data = True
    
    count_found = len(db_data)

    if not db_data:
        response_msg = f"ğŸ” {date_info} tarih aralÄ±ÄŸÄ±nda aradÄ±ÄŸÄ±nÄ±z kriterlere uygun veri bulamadÄ±m."
        conversation_history.append({"role": "user", "content": user_message})
        conversation_history.append({"role": "assistant", "content": response_msg})
        return response_msg

    if not used_cached_data:
        last_successful_data = db_data
        last_date_info = date_info

    # 3. Context HazÄ±rlama
    clean_context = []
    for row in db_data[:150]: 
        content = safe_json_parse(row.get('content'))
        src = row.get('source', '').replace('.csv', '').replace('filtered_', '')
        if isinstance(content, dict) and content.get('kaynak'):
             src = content.get('kaynak')
        clean_context.append({"Platform": src, "Veri": content})

    context_str = json.dumps(clean_context, ensure_ascii=False)

    # 4. Veri Analiz Prompt'u
    system_prompt = f"""
    Sen TrendAI, profesyonel bir veri analistisin.
    
    RAPOR:
    - Tarih: {date_info}
    - Toplam Veri: {count_found} adet
    - HafÄ±za KullanÄ±mÄ±: {'EVET' if used_cached_data else 'HAYIR'}
    
    KURALLAR:
    1. KullanÄ±cÄ±yla sohbet et. Ã–nceki konuÅŸmalarÄ± hatÄ±rla.
    2. Cevaba mutlaka "{date_info} tarihlerinde toplam {count_found} adet veri buldum." gibi bir Ã¶zetle baÅŸla.
    3. JSON verilerini analiz et. Hangi platformdan (Trendyol, Twitter) ne geldiÄŸini belirterek anlat.
    4. "JSON listesi" deme. "GÃ¼ncel verilere gÃ¶re..." de.
    5. KullanÄ±cÄ± "peki fiyatlar?" gibi devam sorusu sorarsa elindeki bu verileri tekrar analiz et.
    """

    messages = [{"role": "system", "content": system_prompt}]
    messages.extend(conversation_history[-4:]) 
    
    messages.append({
        "role": "user", 
        "content": f"MEVCUT VERÄ° SETÄ°:\n{context_str}\n\nKullanÄ±cÄ± Sorusu: {user_message}"
    })

    try:
        response = ai_client.chat.completions.create(
            model=MODEL_NAME, messages=messages, temperature=0.7
        )
        ai_response = response.choices[0].message.content
        
        conversation_history.append({"role": "user", "content": user_message})
        conversation_history.append({"role": "assistant", "content": ai_response})
        
        return ai_response

    except Exception as e:
        return f"AI HatasÄ±: {e}"

async def process_user_input(text: str) -> str:
    return await chat_with_ai(text)

# Hata Ã¶nleyici boÅŸ fonksiyonlar
async def fetch_large_recent_dataset(limit: int = 50): return []
async def save_trend(content: Any): return None
async def get_filtered_raw_data(categories, limit): return []
async def get_trends(limit=20): return []
async def get_products(): return []
async def get_stats(): return []
async def get_latest_trend_data(): return None