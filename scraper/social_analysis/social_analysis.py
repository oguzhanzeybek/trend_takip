import os
import json
import pandas as pd
from openai import OpenAI
from dotenv import load_dotenv
from pathlib import Path
import time
import sys
import re
import datetime
import math 

# --- AYARLAR ---
MODEL_NAME = "openai/gpt-4o-mini" 
BATCH_SIZE = 50 
WAIT_TIME = 1 

BASE_DIR = Path(__file__).resolve().parent

# .env yÃ¼kleme
env_path = None
search_dirs = [BASE_DIR] + list(BASE_DIR.parents)[:3]
for d in search_dirs:
    if (d / '.env').exists():
        env_path = d / '.env'
        load_dotenv(dotenv_path=env_path)
        break

api_key = os.getenv("OPENROUTER_KEY")
if not api_key:
    print("âŒ HATA: OPENROUTER_KEY bulunamadÄ±!")
    sys.exit(1)

client = OpenAI(
    base_url="https://openrouter.ai/api/v1",
    api_key=api_key,
)

def truncate_text(text, max_chars=1000):
    if len(text) > max_chars:
        return text[:max_chars] + "..."
    return text

def clean_data(df):
    initial_len = len(df)
    print(f" ğŸ§¹ Ã–n temizlik... (GiriÅŸ: {initial_len})")
    df = df.dropna(how='all').drop_duplicates() 
    df_temp = df.copy()
    if df_temp.shape[1] > 1:
        df_temp.iloc[:, 1:] = df_temp.iloc[:, 1:].astype(str).apply(
            lambda col: col.apply(lambda x: truncate_text(x, 1000))
        )
    print(f" âœ¨ Veri HazÄ±r: {len(df_temp)} satÄ±r")
    return df_temp.astype(str) 

def save_analysis_json(data, filename):
    output_dir = BASE_DIR / "data"
    output_dir.mkdir(parents=True, exist_ok=True)
    # Dosya ismini standartlaÅŸtÄ±rdÄ±k
    output_path = output_dir / f"analyzed_{filename}.json"
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=4)
    print(f" ğŸ’¾ Analiz Sonucu Kaydedildi: {output_path.name}")

def analyze_data_with_ai(data_chunk, df_columns, is_final_analysis=False, retry=0):
    current_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    
    # Rol TanÄ±mÄ±
    role = "**Sen, verilerin derinliklerindeki hikayeyi okuyan kÄ±demli bir Toplum Bilimci ve Veri Analistisin.**"

    if is_final_analysis:
        # ============================================================
        # FÄ°NAL ANALÄ°Z (STRATEJÄ°K SKORLAR EKLENDÄ°)
        # ============================================================
        prompt_goal = """
        GÃ–REVÄ°N: Sana verilen 'Saha RaporlarÄ±nÄ±' (Batch Summaries) birleÅŸtirerek, uygulamanÄ±n beklediÄŸi EXACT JSON formatÄ±nda ama Ã‡OK DETAYLI bir analiz raporu oluÅŸturmaktÄ±r.
        
        KURALLAR:
        1. Asla kÄ±sa kesme. "GerekÃ§e", "KÃ¶ken" ve "Neden" alanlarÄ±nÄ± doldururken **spesifik Ã¶rnekler, marka isimleri ve olay detaylarÄ±** ver.
        2. Genellemelerden kaÃ§Ä±n. "Ekonomi kÃ¶tÃ¼" deme; "SÃ¼t fiyatlarÄ±ndaki %30 artÄ±ÅŸ ve X marketindeki etiketler" de.
        3. Duygu skorlarÄ±nÄ± (0-100) verilerin yoÄŸunluÄŸuna gÃ¶re gerÃ§ekÃ§i ata.
        
        Ã–NEMLÄ° - STRATEJÄ°K SKORLAMA MANTIÄI:
        - **pazar_sagligi (0-100):** Toplumda Ã¶fke ve stres yÃ¼ksekse dÃ¼ÅŸÃ¼r, umut ve memnuniyet varsa yÃ¼kselt.VERÄ°LERDEN YOLA Ã‡IKARAK ANALÄ°Z ET.
        - **satin_alma_istahi (0-100):** Ä°nsanlar "alamÄ±yoruz" diyorsa dÃ¼ÅŸÃ¼k, "indirim, alÄ±ÅŸveriÅŸ" konuÅŸuyorsa yÃ¼ksek ver.VERÄ°LERDEN YOLA Ã‡IKARAK ANALÄ°Z ET.
        - **viral_etki (0-100):** KonuÅŸulan konular ne kadar yankÄ± uyandÄ±rmÄ±ÅŸ? Herkes aynÄ± ÅŸeyi konuÅŸuyorsa 90+ ver.VERÄ°LERDEN YOLA Ã‡IKARAK ANALÄ°Z ET.
        - **firsat_skoru (0-100):** Bu kriz ortamÄ±nda markalar iÃ§in boÅŸluk var mÄ±? (Ã–rn: Ucuz Ã¼rÃ¼n ihtiyacÄ± = YÃ¼ksek FÄ±rsat).VERÄ°LERDEN YOLA Ã‡IKARAK ANALÄ°Z ET.
        """
        
        data_header = "VERÄ° (Toplanan TÃ¼m ParÃ§alÄ± Analizler):"
        
        # --- JSON FORMATI GÃœNCELLENDÄ°: SKORLAR EKLENDÄ° ---
        json_output_template = f"""
        "analiz_tarihi": "{current_time}",
        "analiz_kaynaÄŸÄ±": "social_media.csv",
        
        "stratejik_skorlar": {{
            "pazar_sagligi": 0, 
            "satin_alma_istahi": 0,
            "viral_etki": 0,
            "firsat_skoru": 0
        }},

        "genel_deÄŸerlendirme": "BURAYA_DETAYLI_PARAGRAF_GELMELÄ° (En az 3-4 cÃ¼mle. Toplumun genel psikolojisini, Ã§eliÅŸkileri ve ana motivasyonlarÄ± edebi ve analitik bir dille Ã¶zetle).",
        "ana_duygular": [
            {{
                "duygu": "Duygu AdÄ± (Ã–rn: Ã–fke)",
                "skor": 0-100,
                "gerekÃ§e": "Bu duygunun kaynaÄŸÄ± nedir? Hangi olaylar tetikledi? (DetaylÄ± yaz)"
            }},
            {{
                "duygu": "Duygu AdÄ± (Ã–rn: Ã‡aresizlik)",
                "skor": 0-100,
                "gerekÃ§e": "Bu duygunun kaynaÄŸÄ± nedir? Hangi olaylar tetikledi? (DetaylÄ± yaz)"
            }},
            {{
                "duygu": "Duygu AdÄ± (Ã–rn: AlaycÄ±lÄ±k)",
                "skor": 0-100,
                "gerekÃ§e": "Bu duygunun kaynaÄŸÄ± nedir? Hangi olaylar tetikledi? (DetaylÄ± yaz)"
            }}
        ],
        "baskin_gundemler": [
            {{
                "konu": "Konu BaÅŸlÄ±ÄŸÄ± 1 (Ã–rn: Kira ZamlarÄ±)",
                "kÃ¶ken": "Bu konunun tartÄ±ÅŸÄ±lma sebebi, verilen Ã¶rnekler ve ÅŸikayetlerin odak noktasÄ±. (DetaylÄ±)"
            }},
            {{
                "konu": "Konu BaÅŸlÄ±ÄŸÄ± 2",
                "kÃ¶ken": "Bu konunun tartÄ±ÅŸÄ±lma sebebi, verilen Ã¶rnekler ve ÅŸikayetlerin odak noktasÄ±. (DetaylÄ±)"
            }},
             {{
                "konu": "Konu BaÅŸlÄ±ÄŸÄ± 3",
                "kÃ¶ken": "Bu konunun tartÄ±ÅŸÄ±lma sebebi, verilen Ã¶rnekler ve ÅŸikayetlerin odak noktasÄ±. (DetaylÄ±)"
            }}
        ],
        "harcama_egilimi_analizi": {{
            "egilim": "TÃ¼keticinin harcama davranÄ±ÅŸÄ± (Ã–rn: LÃ¼ksten kaÃ§Ä±ÅŸ, stoka yÃ¶nelim)",
            "sektor_etkisi": "Hangi sektÃ¶rler nasÄ±l etkileniyor? (Ã–rn: Cafe/Restoran boykotu, Market alÄ±ÅŸveriÅŸi deÄŸiÅŸimi)"
        }},
        "gelecek_tahminleri": [
            {{
                "tahmin": "Gelecek Ã¶ngÃ¶rÃ¼sÃ¼ 1",
                "risk_seviyesi": "YÃ¼ksek/Orta/DÃ¼ÅŸÃ¼k",
                "neden": "Veriye dayalÄ± dayanak noktasÄ±."
            }},
            {{
                "tahmin": "Gelecek Ã¶ngÃ¶rÃ¼sÃ¼ 2",
                "risk_seviyesi": "YÃ¼ksek/Orta/DÃ¼ÅŸÃ¼k",
                "neden": "Veriye dayalÄ± dayanak noktasÄ±."
            }}
        ]
        """
        
        analysis_structure = "Ã‡IKTI FORMATI KESÄ°NLÄ°KLE AÅAÄIDAKÄ° JSON OLMALIDIR. BAÅKA KEY EKLEME VEYA Ã‡IKARMA."

    else:
        # ============================================================
        # BATCH (ARA) ANALÄ°Z - Veri MadenciliÄŸi
        # ============================================================
        prompt_goal = "GÃ¶revin bu 50 satÄ±rlÄ±k verideki 'AltÄ±n DeÄŸerindeki' detaylarÄ± Ã§Ä±karmaktÄ±r. Genelleme yapma, Ä°SÄ°M, MARKA, OLAY ve DUYGU yakala."
        data_header = f"VERÄ° PARÃ‡ASI: {data_chunk}"
        
        analysis_structure = "Sadece aÅŸaÄŸÄ±daki basit yapÄ±yÄ± kullan:"
        
        json_output_template = """
        "ozet_duygu": "BaskÄ±n his",
        "tespit_edilen_detaylar": "Metinde geÃ§en Markalar, KiÅŸiler, Yerler, Fiyatlar, Olaylar (Hepsini yaz)",
        "ana_konu": "Ä°nsanlar ne konuÅŸuyor?",
        "detayli_kanit": "Neden bÃ¶yle dÃ¼ÅŸÃ¼nÃ¼yorlar? (AlÄ±ntÄ± yap)"
        """

    prompt = f"""
    SADECE JSON Ã‡IKTISI ÃœRET.
    
    Rol: {role}
    GÃ¶rev: {prompt_goal}
    
    {analysis_structure}
    
    {data_header}
    
    Ä°stenen JSON ÅemasÄ±:
    {{
      {json_output_template}
    }}
    """
    
    try:
        if retry == 0:
            print(f"    ğŸ’¬ AI Ã‡alÄ±ÅŸÄ±yor... ({'FÄ°NAL RAPORLAMA' if is_final_analysis else 'VERÄ° MADENCÄ°LÄ°ÄÄ°'})")
        
        completion = client.chat.completions.create(
            extra_headers={"HTTP-Referer": "http://localhost", "X-Title": "TrendAI"},
            model=MODEL_NAME,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.5 if not is_final_analysis else 0.7, 
        )
        
        resp = completion.choices[0].message.content
        
        if "```" in resp:
            match = re.search(r"```json\s*(.*?)\s*```", resp, re.DOTALL)
            resp = match.group(1).strip() if match else resp.replace("```", "").strip()
        
        resp = re.sub(r'//.*', '', resp)
        
        return json.loads(resp)
    
    except Exception as e:
        if retry < 2:
            time.sleep(3)
            return analyze_data_with_ai(data_chunk, df_columns, is_final_analysis, retry + 1)
        print(f"âŒ Hata: {e}")
        return None

def process_social_media_analysis():
    raw_data_dir = BASE_DIR.parent / "ai_filter" / "Raw_data"
    filename = "social_media.csv"
    
    debug_file_path = BASE_DIR / "data" / "batch_summaries_debug.txt"
    
    print(f"ğŸš€ {filename} ANALÄ°Z SÃœRECÄ° BAÅLATILIYOR...")
    
    try:
        df = pd.read_csv(raw_data_dir / filename, dtype=str, low_memory=False).fillna("")
    except:
        print("âŒ Dosya okunamadÄ±.")
        return
    
    df_clean = clean_data(df)
    total_rows = len(df_clean)
    
    if total_rows == 0: return

    num_batches = math.ceil(total_rows / BATCH_SIZE)
    intermediate_summaries = []
    
    with open(debug_file_path, "w", encoding="utf-8") as f: f.write("")

    print(f" ğŸ“ {total_rows} satÄ±r veri, {num_batches} aÅŸamada iÅŸlenecek.")
    
    for i in range(num_batches):
        start = i * BATCH_SIZE
        end = min((i + 1) * BATCH_SIZE, total_rows)
        batch_df = df_clean.iloc[start:end]
        
        batch_res = analyze_data_with_ai(batch_df.to_string(index=False), [], is_final_analysis=False)
        
        if batch_res:
            summary_text = (
                f"RAPOR {i+1}:\n"
                f"Konu: {batch_res.get('ana_konu')}\n"
                f"Tespit Edilen VarlÄ±klar/Markalar: {batch_res.get('tespit_edilen_detaylar')}\n"
                f"Duygu: {batch_res.get('ozet_duygu')}\n"
                f"KanÄ±t/Detay: {batch_res.get('detayli_kanit')}\n"
            )
            intermediate_summaries.append(summary_text)
            print(f"  âœ”ï¸ Batch {i+1} Tamam: {batch_res.get('ana_konu')}")
            
            with open(debug_file_path, "a", encoding="utf-8") as f:
                f.write(summary_text + "\n---\n")
        
        time.sleep(WAIT_TIME)

    if not intermediate_summaries:
        return

    print("\nğŸ§  TÃœM VERÄ°LER TOPLANDI. FÄ°NAL FORMATI OLUÅTURULUYOR...")
    
    final_input = "\n".join(intermediate_summaries)
    
    final_res = analyze_data_with_ai(final_input, [], is_final_analysis=True)
    
    if final_res:
        save_analysis_json(final_res, "social_media_ultra_detailed_sentiment")
        print("\nğŸ‰ ANALÄ°Z TAMAMLANDI! Ã‡Ä±ktÄ± formatÄ± uygulamanÄ±zla uyumludur.")
    else:
        print("âŒ Final rapor oluÅŸturulamadÄ±.")

if __name__ == "__main__":
    process_social_media_analysis()