import os
import json
import pandas as pd
from openai import OpenAI
from dotenv import load_dotenv
from pathlib import Path
import time
import sys
import re
import datetime
import math 

# --- AYARLAR ---
# En stabil, en hÄ±zlÄ± ve maliyeti en dÃ¼ÅŸÃ¼k model: GPT-4o-mini
MODEL_NAME = "openai/gpt-4o-mini" 

# Stabil ve hÄ±zlÄ± iÅŸlem iÃ§in ideal ayarlar
BATCH_SIZE = 50 # Her bir AI isteÄŸi iÃ§in 50 satÄ±r veri
WAIT_TIME = 1 # 1 saniye dinlenme

# --- BAÄLANTI ---
BASE_DIR = Path(__file__).resolve().parent

# .env dosyasÄ±nÄ± bulma ve yÃ¼kleme
env_path = None
search_dirs = [BASE_DIR] + list(BASE_DIR.parents)[:3]
for d in search_dirs:
    if (d / '.env').exists():
        env_path = d / '.env'
        load_dotenv(dotenv_path=env_path)
        break

api_key = os.getenv("OPENROUTER_KEY")
if not api_key:
    print("âŒ HATA: OPENROUTER_KEY bulunamadÄ±!")
    sys.exit(1)

client = OpenAI(
    base_url="https://openrouter.ai/api/v1",
    api_key=api_key,
)

# --- YARDIMCI FONKSÄ°YONLAR ---

def truncate_text(text, max_chars=1000):
    """Token maliyetini dÃ¼ÅŸÃ¼rmek iÃ§in metni kÄ±saltÄ±r."""
    if len(text) > max_chars:
        return text[:max_chars] + "..."
    return text

def clean_data(df):
    """
    TEMÄ°ZLÄ°K VE KIRPMA
    """
    initial_len = len(df)
    print(f"  ğŸ§¹ Ã–n temizlik... (GiriÅŸ: {initial_len})")
    
    # SADECE tamamen boÅŸ satÄ±rlarÄ± ve duplike satÄ±rlarÄ± atar
    df = df.dropna(how='all').drop_duplicates() 
    
    df_temp = df.copy()
    if df_temp.shape[1] > 1:
        # Ä°ndeks 1'den (ikinci sÃ¼tun) sonrasÄ± kÄ±rpÄ±lÄ±r.
        df_temp.iloc[:, 1:] = df_temp.iloc[:, 1:].astype(str).apply(
            lambda col: col.apply(lambda x: truncate_text(x, 1000))
        )
    
    print(f"  âœ¨ Veri HazÄ±r: {len(df_temp)} satÄ±r")
    return df_temp.astype(str) 

def get_output_file_path(filename):
    # Data klasÃ¶rÃ¼ yoksa oluÅŸtur
    output_dir = BASE_DIR / "data"
    output_dir.mkdir(parents=True, exist_ok=True)
    return output_dir / f"analyzed_{filename}.json"

def save_analysis_json(data, filename):
    output_path = get_output_file_path(filename)
    
    # JSON dosyasÄ±nÄ± oluÅŸturup kaydet
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=4)
    print(f"  ğŸ’¾ Analiz Sonucu Kaydedildi: {output_path.name}")


# ğŸš¨ GÃœNCEL VE ULTRA DETAYLI ANALÄ°Z FONKSÄ°YONU ğŸš¨
def analyze_data_with_ai(data_chunk, df_columns, is_final_analysis=False, retry=0):
    column_names = ", ".join(df_columns) 
    current_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    
    # ROL TANIMI VE TALÄ°MATLAR, DETAY VE UZATMA ODAKLI GÃœÃ‡LENDÄ°RÄ°LDÄ°
    role = "**TÃ¼rkiye'nin en Ã¼st dÃ¼zey Sosyal Medya ve Toplumsal NabÄ±z BaÅŸ Analisti'sin. HazÄ±rladÄ±ÄŸÄ±n rapor, siyaset ve iÅŸ dÃ¼nyasÄ± iÃ§in kritik bir 'Sosyal Zeka Raporu'dur. Her bir konuyu en az 4-5 cÃ¼mle ile detaylandÄ±r.**"
    
    if is_final_analysis:
        # FÄ°NAL ANALÄ°Z PROMPT'u: Ã‡OK DETAYLI, UZUN VE GEREKÃ‡ELÄ° ANALÄ°Z TALEP EDÄ°LÄ°YOR
        prompt_goal = "GÃ¶revin, saÄŸlanan TÃœM ara analiz Ã¶zetlerini okuyarak, halkÄ±n gÃ¼ncel duygu durumunu, temel eÄŸilimlerini, beklentilerini ve **geleceÄŸe yÃ¶nelik tahminleri iÃ§eren BÃœTÃœNSEL, GEREKÃ‡ELÄ° ve AZAMÄ° DETAYDA** bir sosyal zeka raporu hazÄ±rlamaktÄ±r. **HER ALANI EN UZUN ÅEKÄ°LDE, TÃœM ANALÄ°Z EDÄ°LEN VERÄ°LERÄ° YANSITARAK DOLDUR.**"
        data_header = "VERÄ° (Toplu iÅŸlerden gelen ara analiz Ã¶zetleri):"
        analysis_structure = """
    1. **Ana Duygu Durumu ve GerekÃ§esi:** TÃ¼m Ã¶zetlerde baskÄ±n olan nihai duygu nedir? Her bir duygu iÃ§in 0-100 arasÄ± bir gÃ¼Ã§ skoru ver. Bu skorlarÄ±n **nedenini ve toplumsal yansÄ±masÄ±nÄ± Ã‡OK DETAYLI** aÃ§Ä±kla.
    2. **BaskÄ±n GÃ¼ndemler ve KÃ¶kenleri:** En Ã§ok tekrar eden/Ã¶ne Ã§Ä±kan 3 temel konu ne? Her bir konunun sosyal medya verilerindeki **tetikleyicisini/kÃ¶kenini, alt baÅŸlÄ±klarÄ±nÄ± ve etki alanlarÄ±nÄ±** detaylÄ±ca aÃ§Ä±kla.
    3. **Harcama EÄŸilimi ve Etkisi (Makro Analiz):** Genel ruh haline bakarak, harcama eÄŸilimleri hakkÄ±nda **Ã‡OK DETAYLI bir Ã§Ä±karÄ±m** yap. Bu eÄŸilimin **tÃ¼ketici davranÄ±ÅŸÄ±nÄ± ve hangi sektÃ¶rleri nasÄ±l etkileyeceÄŸini** kapsamlÄ±ca belirt.
    4. **Gelecek Tahmini ve Riskler (3 AylÄ±k Perspektif):** Ã–nÃ¼mÃ¼zdeki 3 ay iÃ§in toplumsal tepki ve eÄŸilimler konusunda 3-4 **somut, gerekÃ§eli ve detaylÄ± tahmin**de bulun. Tahminlerin doÄŸruluk/gerÃ§ekleÅŸme **risklerini** ve bu riskleri azaltma/yÃ¶netme Ã¶nerilerini belirt.
    5. Ã‡IKTI sadece ve sadece tek bir JSON nesnesi olmalÄ±dÄ±r. LÃ¼tfen aÃ§Ä±klama veya analiz metni YAPMA. SADECE JSON dÃ¶ndÃ¼r.
        """
        json_output_template = f"""
    "analiz_tarihi": "{current_time}",
    "analiz_kaynaÄŸÄ±": "social_media.csv",
    "genel_deÄŸerlendirme": "Verilere gÃ¶re halkÄ±n anlÄ±k durumunu ve genel toplumsal nabzÄ± Ã¶zetleyen, **minimum 5-7 cÃ¼mlelik, derinlemesine ve kapsamlÄ±** bir paragraf. Analiz edilen tÃ¼m verilerin Ã¶zeti bu paragrafta yer almalÄ±dÄ±r.",
    "ana_duygular": [
      {{ "duygu": "EndiÅŸe", "skor": 75, "gerekÃ§e": "EndiÅŸe skorunun yÃ¼ksek olmasÄ±nÄ±n ardÄ±ndaki temel 3-4 gerekÃ§e. HalkÄ±n yaÅŸam kalitesine etkileri, ekonomik kaygÄ±lar ve belirsizlik algÄ±sÄ± bu bÃ¶lÃ¼mde Ã‡OK DETAYLI aÃ§Ä±klanmalÄ±dÄ±r." }},
      {{ "duygu": "NeÅŸe/Pozitiflik", "skor": 40, "gerekÃ§e": "Pozitiflik seviyesini belirleyen unsurlarÄ±n kÄ±sa aÃ§Ä±klamasÄ±. Bu duygularÄ±n geÃ§ici mi kalÄ±cÄ± mÄ± olduÄŸu, hangi sosyal aktivitelerle tetiklendiÄŸi ve genel endiÅŸeyi nasÄ±l dengelemeye Ã§alÄ±ÅŸtÄ±ÄŸÄ± detaylandÄ±rÄ±lmalÄ±dÄ±r." }}
    ],
    "baskin_gundemler": [
      {{ "konu": "Ekonomi ve Enflasyon", "kÃ¶ken": "Sosyal medyada en Ã§ok paylaÅŸÄ±lan enflasyon ve hayat pahalÄ±lÄ±ÄŸÄ± ile ilgili somut veriler/tepkiler. Bu konunun alt baÅŸlÄ±klarÄ± (gÄ±da, kira, akaryakÄ±t) ve siyasi yansÄ±malarÄ± kapsamlÄ±ca aÃ§Ä±klanmalÄ±dÄ±r." }}, 
      {{ "konu": "Sosyal Hayat ve KaÃ§Ä±ÅŸ", "kÃ¶ken": "HalkÄ±n stres yÃ¶netimi iÃ§in yÃ¶neldiÄŸi kaÃ§Ä±ÅŸ temalÄ± iÃ§eriklerin (gezi, dizi, oyun vb.) oranÄ±. Bu kaÃ§Ä±ÅŸÄ±n sosyal ve psikolojik nedenleri ve bu iÃ§eriklere olan yÃ¼ksek talebin ardÄ±ndaki toplumsal boÅŸluk detaylandÄ±rÄ±lmalÄ±dÄ±r." }},
      {{ "konu": "SaÄŸlÄ±k, GÃ¼venlik ve Kurumsal GÃ¼ven", "kÃ¶ken": "Pandemi sonrasÄ± saÄŸlÄ±k endiÅŸelerinin kalÄ±cÄ±lÄ±ÄŸÄ± ve gÃ¼venlik konularÄ±nÄ±n (Ã¶zellikle siber/bireysel gÃ¼venlik) sosyal medyada artan paylaÅŸÄ±mlarÄ±. Kurumlara olan gÃ¼venin bu konularla nasÄ±l iliÅŸkilendiÄŸi aÃ§Ä±klanmalÄ±dÄ±r." }}
    ],
    "harcama_egilimi_analizi": {{
        "egilim": "HalkÄ±n harcama davranÄ±ÅŸÄ±ndaki ana kaymalar ve bu kaymalarÄ±n ardÄ±ndaki psikoloji. Tasarruf eÄŸiliminin hangi gelir gruplarÄ±nda ve nasÄ±l kendini gÃ¶sterdiÄŸi Ã‡OK DETAYLI belirtilmelidir.",
        "sektor_etkisi": "Perakende, HORECA, Teknoloji ve Temel GÄ±da sektÃ¶rlerindeki hacim dÃ¼ÅŸÃ¼ÅŸleri/artÄ±ÅŸlarÄ± ve bu durumun nedenleri. Ã–zellikle hangi alt sektÃ¶rlerin (Ã¶rn: lÃ¼ks kahve, ikinci el Ã¼rÃ¼nler) Ã¶ne Ã§Ä±ktÄ±ÄŸÄ± detaylÄ± analiz edilmelidir."
    }},
    "gelecek_tahminleri": [
        {{ "tahmin": "Ã–nÃ¼mÃ¼zdeki 3 ayda X konusundaki toplumsal tepkiler artacaktÄ±r.", "risk_seviyesi": "Orta/YÃ¼ksek", "neden": "Bu tahmine neden olan temel veri sinyali ve sosyo-ekonomik gÃ¶stergeler. Bu tahmini destekleyen spesifik sosyal medya trendleri belirtilmelidir." }},
        {{ "tahmin": "Y sektÃ¶rÃ¼ne yÃ¶nelik ilgi, toplumsal kaÃ§Ä±ÅŸ ihtiyacÄ±ndan dolayÄ± bir miktar ivme kazanacaktÄ±r. Ancak, Z faktÃ¶rÃ¼ bu ivmeyi sÄ±nÄ±rlandÄ±racaktÄ±r.", "risk_seviyesi": "DÃ¼ÅŸÃ¼k/Orta", "neden": "Bu tahmine neden olan temel veri sinyali. Bu durumun hangi demografik gruplarda daha belirgin olduÄŸu detaylandÄ±rÄ±lmalÄ±dÄ±r." }},
        {{ "tahmin": "Kurumsal ve bireysel gÃ¼venlik talepleri sosyal medyada daha fazla gÃ¼ndem olacak ve bu alanda hizmet beklentisi artacaktÄ±r.", "risk_seviyesi": "Orta", "neden": "Bu tahmine neden olan temel veri sinyali ve beklentinin kaynaÄŸÄ± detaylÄ±ca aÃ§Ä±klanmalÄ±dÄ±r." }}
    ]
        """
    else:
        # ARA ANALÄ°Z (BATCH) PROMPT'u: DetaylÄ± ve KapsamlÄ± GerekÃ§e OdaklÄ±
        prompt_goal = "GÃ¶revin, saÄŸlanan sosyal medya verilerinden yola Ã§Ä±karak bu kÃ¼Ã§Ã¼k veri grubunun (batch) genel duygu durumunu ve eÄŸilimlerini analiz etmektir. **Nihai BÃ¼tÃ¼nsel Analiz iÃ§in kullanÄ±lacak Ã‡OK DETAYLI ve KAPSAMLI gerekÃ§eli bir Ã¶n-Ã¶zet** Ã¼ret. HalkÄ±n anlÄ±k beklentisi, ne istediÄŸi ve hangi somut olaylara tepki verdiÄŸi her aÃ§Ä±dan deÄŸerlendirilmelidir."
        data_header = f"VERÄ° (Kolon Ä°simleri hariÃ§tir, yukarÄ±daki listeye bakÄ±nÄ±z): {data_chunk}"
        analysis_structure = """
    1. **Ã–zet Duygu:** Bu veri parÃ§acÄ±ÄŸÄ±nda baskÄ±n olan ana duygu nedir? 
    2. **Duygu GerekÃ§esi:** Bu duygunun neden baskÄ±n olduÄŸunu aÃ§Ä±klayan **minimum 3 cÃ¼mlelik, Ã§ok somut ve detaylÄ± bir gerekÃ§e**.
    3. **Ã–zet Konu:** Bu veri parÃ§acÄ±ÄŸÄ±nda en Ã§ok konuÅŸulan ana konu nedir? 
    4. **Konu GerekÃ§esi:** Bu konunun neden Ã¶ne Ã§Ä±ktÄ±ÄŸÄ±nÄ± ve halkÄ±n bu konudaki **ana beklentisini** aÃ§Ä±klayan **minimum 3 cÃ¼mlelik, Ã§ok somut ve detaylÄ± bir gerekÃ§e**.
    5. Ã‡IKTI sadece ve sadece tek bir JSON nesnesi olmalÄ±dÄ±r.
        """
        json_output_template = """
      "ozet_duygu": "EndiÅŸe",
      "duygu_gerekcesi": "Verilerde sÃ¼rekli olarak ekonomik zorluklar, yÃ¼ksek enflasyonun bireylerin satÄ±n alma gÃ¼cÃ¼nÃ¼ nasÄ±l tÃ¼kettiÄŸi ve fatura Ã¶deme zorluklarÄ± gibi somut yaÅŸam zorluklarÄ± geÃ§mektedir. Bu, birikim yapamama ve gelecek kaygÄ±sÄ± ÅŸeklinde kendini gÃ¶steriyor.",
      "ozet_konu": "Hayat PahalÄ±lÄ±ÄŸÄ± ve Temel Ä°htiyaÃ§lar",
      "konu_gerekcesi": "Veri setindeki gÃ¶nderilerin %70'inden fazlasÄ± direkt olarak gÄ±da fiyatlarÄ±, kira artÄ±ÅŸlarÄ± ve akaryakÄ±t zamlarÄ±na deÄŸinmektedir. HalkÄ±n ana beklentisi, temel yaÅŸam maliyetlerinin kontrol altÄ±na alÄ±nmasÄ± ve alÄ±m gÃ¼cÃ¼nÃ¼n stabilize edilmesidir. Bu konunun Ã¶ne Ã§Ä±kma nedeni, gÃ¼nlÃ¼k yaÅŸamÄ± en direkt etkileyen unsur olmasÄ±dÄ±r."
        """


    # PROMPT YapÄ±sÄ±
    prompt = f"""
    SEN KRÄ°TÄ°K BÄ°R ROLÃœ ÃœSTLENÄ°YORSUN. SADECE Ä°STENEN JSON Ã‡IKTISINI ÃœRET. BAÅKA HÄ°Ã‡BÄ°R AÃ‡IKLAMA VEYA GÄ°RÄ°Å METNÄ° KULLANMA.
    
    Sen, {role}
    {prompt_goal}
    
    AMACIN: Bu veriyi okuyarak, toplumu anlayan bir iÅŸ zekasÄ± Ã¼retmektir.
    
    GÃ–REV: AÅŸaÄŸÄ±daki sosyal medya verilerini **{ 'BÃœTÃœNSEL' if is_final_analysis else 'ARA' }** olarak analiz et.
    Kolon Ä°simleri (SÄ±rayla): [{column_names}]
    
    {analysis_structure}
    
    {data_header}
    
    Ã‡IKTI: {{
      {json_output_template}
    }}
    """
    
    try:
        if retry == 0:
            print(f"    ğŸ’¬ AI Analizi BaÅŸlatÄ±lÄ±yor... ({'Nihai Ã‡OK DETAYLI Rapor' if is_final_analysis else 'Batch - KapsamlÄ± GerekÃ§eli Ã–zet'})")
        
        completion = client.chat.completions.create(
            extra_headers={"HTTP-Referer": "http://localhost", "X-Title": "SentimentAnalyzer"},
            model=MODEL_NAME,
            messages=[{"role": "user", "content": prompt}],
            temperature=0.5, # Maksimum detay ve aÃ§Ä±klama iÃ§in sÄ±caklÄ±k 0.5'e yÃ¼kseltildi
        )
        
        resp = completion.choices[0].message.content
        
        # JSON Temizleme (Mevcut koddan korundu)
        if "```" in resp:
            match = re.search(r"```json\s*(.*?)\s*```", resp, re.DOTALL)
            if match:
                resp = match.group(1).strip()
            else:
                resp = resp.replace("```", "").strip()
        
        resp = re.sub(r'//.*', '', resp) 
        
        return json.loads(resp)
    
    except Exception as e:
        err = str(e)
        if "402" in err or "insufficient_quota" in err:
            print("\nâŒ HATA: Yetersiz Bakiye! LÃ¼tfen OpenRouter'a kredi yÃ¼kleyin.")
            sys.exit(1)
            
        if retry < 2:
            print(f"      âš ï¸ GeÃ§ici Hata ({e.__class__.__name__}). Tekrar deneniyor... ({retry+1})")
            time.sleep(5)
            return analyze_data_with_ai(data_chunk, df_columns, is_final_analysis, retry + 1)
            
        print(f"\nâŒ Kritik Hata. AI'dan analiz alÄ±namadÄ±. Hata: {err}")
        return None

# --- ANA DÃ–NGÃœ (Batch Ä°ÅŸleme MantÄ±ÄŸÄ± Korundu) ---
def process_social_media_analysis():
    # --- DEÄÄ°ÅÄ°KLÄ°K BURADA: Dinamik Dosya Yolu ---
    # Eski sabit yol yerine, scriptin olduÄŸu yerden yola Ã§Ä±karak raw_data'yÄ± buluyoruz.
    raw_data_dir = BASE_DIR.parent / "ai_filter" / "Raw_data"
    
    # Ã‡Ä±ktÄ± klasÃ¶rÃ¼ kontrolÃ¼ (varsa kullan, yoksa oluÅŸtur)
    output_dir = BASE_DIR / "data"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    filename = "social_media.csv"
    
    print(f"ğŸ“‚ Okunacak: {raw_data_dir / filename}")
    print(f"ğŸ’ Model: {MODEL_NAME} (HAZIR)")
    print("------------------------------------------------")

    if not (raw_data_dir / filename).exists():
        print(f"âŒ HATA: {filename} dosyasÄ± bulunamadÄ±. LÃ¼tfen yolu kontrol edin:")
        print(f"   Aranan Yer: {raw_data_dir / filename}")
        return

    print(f"\nğŸš€ {filename} TOPLUMSAL NABIZ ANALÄ°ZÄ° BAÅLIYOR...")
    
    try:
        # TÃ¼m veriyi oku
        df = pd.read_csv(raw_data_dir / filename, dtype=str, low_memory=False).fillna("")
    except Exception as e:
        print(f"âŒ Dosya okuma hatasÄ±: {e}")
        return
    
    # Veriyi temizle ve kÄ±rp
    df_clean = clean_data(df)
    total_rows = len(df_clean)
    
    if total_rows == 0:
        print("âŒ Temizlenecek veri bulunamadÄ±. Analiz yapÄ±lamÄ±yor.")
        return
    
    # --- BATCH Ä°ÅLEME MANTIÄI ---
    
    num_batches = math.ceil(total_rows / BATCH_SIZE)
    intermediate_summaries = []
    df_columns = df_clean.columns.tolist()

    print(f"  ğŸ“ Toplam {total_rows} satÄ±r, {num_batches} toplu iÅŸ (batch) halinde iÅŸlenecek.")
    
    # ParÃ§alarÄ± dÃ¶ngÃ¼de iÅŸleme
    for i in range(num_batches):
        start_index = i * BATCH_SIZE
        end_index = min((i + 1) * BATCH_SIZE, total_rows)
        
        batch_df = df_clean.iloc[start_index:end_index]
        batch_data_chunk = batch_df.to_string(header=False, index=False)
        
        print(f"\n--- Batch {i+1}/{num_batches} (SatÄ±r {start_index} - {end_index-1}) ---")
        
        # Ara analizi yap
        batch_analysis = analyze_data_with_ai(batch_data_chunk, df_columns, is_final_analysis=False)
        
        if batch_analysis:
            # Ara sonuÃ§larÄ± listeye ekle (ArtÄ±k daha detaylÄ± Ã¶zetler alÄ±nÄ±yor)
            summary = (
                f"Batch {i+1} Ã–zeti: Ana Duygu: {batch_analysis.get('ozet_duygu', 'Bilinmiyor')} "
                f"(GerekÃ§e: {batch_analysis.get('duygu_gerekcesi', 'Yok')}), "
                f"Ana Konu: {batch_analysis.get('ozet_konu', 'Bilinmiyor')} "
                f"(GerekÃ§e: {batch_analysis.get('konu_gerekcesi', 'Yok')})"
            )
            intermediate_summaries.append(summary)
            print(f"  âœ”ï¸ Batch {i+1} TamamlandÄ±. Ã–zet: {summary}")
        else:
            print(f"  âŒ Batch {i+1} Analizi baÅŸarÄ±sÄ±z. AtlanÄ±yor.")

        time.sleep(WAIT_TIME)

    if not intermediate_summaries:
        print("\nâŒ HiÃ§bir batch analiz edilemedi. Nihai analiz yapÄ±lamÄ±yor.")
        return

    # --- NÄ°HAÄ° ANALÄ°Z ---
    final_input_data = "\n".join(intermediate_summaries)
    print("\n================================================")
    print("ğŸ§  ARA ANALÄ°ZLER BÄ°RLEÅTÄ°RÄ°LÄ°YOR: NIHAI Ã‡OK DETAYLI ANALÄ°Z BAÅLIYOR...")
    print("================================================")
    
    # Ara Ã¶zetleri kullanarak nihai bÃ¼tÃ¼nsel analizi yap
    final_analysis_result = analyze_data_with_ai(
        data_chunk=final_input_data, 
        df_columns=["ozet_duygu", "duygu_gerekcesi", "ozet_konu", "konu_gerekcesi"], 
        is_final_analysis=True
    )
    
    if final_analysis_result:
        # Sonucu JSON dosyasÄ±na kaydet
        save_analysis_json(final_analysis_result, filename.split('.')[0] + "_ultra_detailed_sentiment")
        print("\nğŸ‰ TOPLUMSAL NABIZ ANALÄ°ZÄ° BAÅARIYLA TAMAMLANDI!")
    else:
        print("\nâŒ Nihai BÃ¼tÃ¼nsel Analiz baÅŸarÄ±sÄ±z oldu.")


if __name__ == "__main__":
    process_social_media_analysis()