import sys
import time
import csv
import random
import concurrent.futures
import threading
from pathlib import Path
from selenium.webdriver.common.by import By

# --- 1. YOL AYARLARI ---
# Dosya Konumu: scraper/online_shopping/alibaba/alibaba.py
CURRENT_DIR = Path(__file__).resolve().parent
# Scraper kÃ¶k dizinine Ã§Ä±k (alibaba -> online_shopping -> scraper)
# DÃœZELTME: 3 tane parent fazla geliyor, 2 tane yeterli.
ROOT_DIR = CURRENT_DIR.parent.parent

# KÃ¶k dizini sisteme ekle
sys.path.append(str(ROOT_DIR))

# --- 2. MERKEZÄ° DRIVER Ã‡AÄRISI ---
try:
    from core.driver_manager import get_chrome_driver
except ImportError:
    # EÄŸer yukarÄ±daki yol Ã§alÄ±ÅŸmazsa (IDE vs. farklÄ± Ã§alÄ±ÅŸtÄ±rÄ±rsa) bir Ã¼stÃ¼ dene
    # Ama normalde yukarÄ±daki ROOT_DIR doÄŸru olmalÄ±.
    sys.path.append(str(ROOT_DIR.parent))
    try:
        from scraper.core.driver_manager import get_chrome_driver
    except ImportError:
        # Son Ã§are manuel import denemesi
        print("âš ï¸ Core modÃ¼lÃ¼ bulunamadÄ±, yol ayarlarÄ±nÄ± kontrol edin.")
        raise

# --- AYARLAR ---
BASE_DIR = CURRENT_DIR
SAVE_PATH = BASE_DIR
MAX_WORKERS = 3 
driver_init_lock = threading.Lock() # Thread gÃ¼venliÄŸi iÃ§in kilit

# 1. ADIM: KATEGORÄ° LÄ°NKLERÄ°NÄ° TOPLA
def get_all_category_links():
    print("ğŸ“‹ Kategori listesi hazÄ±rlanÄ±yor (Ana bot baÅŸlatÄ±lÄ±yor)...")
    
    links_data = []
    driver = None
    
    try:
        # Ã‡akÄ±ÅŸmayÄ± Ã¶nlemek iÃ§in driver aÃ§Ä±lÄ±ÅŸÄ±nÄ± kilitliyoruz
        with driver_init_lock:
            # MERKEZÄ° SÄ°STEMDEN DRIVER AL
            driver = get_chrome_driver()
        
        driver.set_page_load_timeout(60)

        print("ğŸŒ Alibaba Rank sayfasÄ±na gidiliyor...")
        driver.get("https://sale.alibaba.com/p/rank/list.html")
        time.sleep(8)
        
        # SayfayÄ± aÅŸaÄŸÄ± kaydÄ±r
        driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
        time.sleep(3)
        
        # Linkleri topla
        all_links = driver.find_elements(By.CSS_SELECTOR, "a[href*='/p/rank/detail']")
        print(f"ğŸ” Sayfada {len(all_links)} potansiyel link bulundu.")

        seen_urls = set()
        for link in all_links:
            try:
                # Sadece gÃ¶rsel iÃ§eren (gerÃ§ek kategori) kutularÄ± al
                if len(link.find_elements(By.TAG_NAME, "img")) > 0:
                    url = link.get_attribute("href")
                    text = link.text.strip().split("\n")[0]
                    if not text: text = "Kategori"
                    
                    if url and url not in seen_urls:
                        seen_urls.add(url)
                        links_data.append((text, url))
            except: continue
            
    except Exception as e:
        print(f"âŒ Link toplama hatasÄ±: {e}")
    finally:
        if driver:
            try:
                driver.quit()
            except: pass
    
    return links_data

# 2. ADIM: Ä°ÅÃ‡Ä° FONKSÄ°YONU
def process_batch(category_list, worker_id):
    print(f"âŒ› Bot-{worker_id} tarayÄ±cÄ± sÄ±rasÄ± bekliyor...")
    
    driver = None
    # Thread gÃ¼venliÄŸi iÃ§in driver aÃ§arken kilit kullan
    with driver_init_lock:
        try:
            # MERKEZÄ° SÄ°STEMDEN DRIVER AL
            driver = get_chrome_driver()
            print(f"ğŸŸ¢ Bot-{worker_id} tarayÄ±cÄ±sÄ± AÃ‡ILDI.")
            time.sleep(2)
        except Exception as e:
            print(f"âŒ Bot-{worker_id} tarayÄ±cÄ± aÃ§Ä±lÄ±ÅŸ hatasÄ±: {e}")
            return []

    print(f"ğŸš€ Bot-{worker_id} iÅŸleme baÅŸladÄ±. ({len(category_list)} kategori)")
    
    batch_results = []
    
    for index, (cat_name, cat_url) in enumerate(category_list):
        print(f"   [Bot-{worker_id}] {index+1}/{len(category_list)}: {cat_name}")
        
        try:
            driver.get(cat_url)
            time.sleep(random.uniform(3, 5)) 

            # KaydÄ±rma iÅŸlemi
            for _ in range(3):
                driver.execute_script("window.scrollBy(0, 1000);")
                time.sleep(1)

            cards = driver.find_elements(By.CLASS_NAME, "hugo4-pc-grid-item")
            
            count = 0
            for card in cards:
                if count >= 20: break # Her kategori iÃ§in max 20 Ã¼rÃ¼n
                try:
                    try: 
                        t_el = card.find_element(By.CSS_SELECTOR, ".subject span")
                        title = t_el.get_attribute("title") or t_el.text.strip()
                    except: title = "BaÅŸlÄ±k Yok"
                    
                    try: price = card.find_element(By.CLASS_NAME, "hugo4-product-price-area").text.strip()
                    except: price = "-"
                    
                    try: moq = card.find_element(By.CLASS_NAME, "moq-pc").text.strip()
                    except: moq = "-"
                    
                    try: 
                        if card.tag_name == 'a': link = card.get_attribute("href")
                        else: link = card.find_element(By.TAG_NAME, "a").get_attribute("href")
                    except: link = ""

                    # Veriyi ekle
                    batch_results.append([cat_name, title, price, moq, link])
                    count += 1
                except: continue
                
        except Exception as e:
            print(f"   âš ï¸ [Bot-{worker_id}] Sayfa hatasÄ± ({cat_name}): {e}")
            continue
            
    # Temizlik
    if driver:
        try:
            driver.quit()
            print(f"ğŸ Bot-{worker_id} kapatÄ±ldÄ±.")
        except: pass

    return batch_results

# --- ANA Ã‡ALIÅTIRMA ---
if __name__ == "__main__":
    
    start_time = time.time()
    
    # 1. Linkleri Al
    all_categories = get_all_category_links()
    print(f"âœ… Toplam {len(all_categories)} kategori listesi hazÄ±r.")
    
    if not all_categories:
        print("âŒ HiÃ§ kategori bulunamadÄ±, script sonlandÄ±rÄ±lÄ±yor.")
        sys.exit()

    # 2. Ä°ÅŸleri BÃ¶l
    chunk_size = len(all_categories) // MAX_WORKERS + 1
    chunks = [all_categories[i:i + chunk_size] for i in range(0, len(all_categories), chunk_size)]
    
    # 3. Paralel Ã‡alÄ±ÅŸtÄ±r
    all_final_data = []
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = []
        for i, chunk in enumerate(chunks):
            if chunk:
                futures.append(executor.submit(process_batch, chunk, i+1))
        
        for future in concurrent.futures.as_completed(futures):
            try:    
                data = future.result()
                all_final_data.extend(data)
            except Exception as e:
                print(f"âŒ Bir thread Ã§Ã¶ktÃ¼: {e}")

    # 4. Kaydet
    file_path = SAVE_PATH / "alibaba.csv"
    
    try:
        with open(file_path, "w", newline="", encoding="utf-8-sig") as file:
            writer = csv.writer(file)
            writer.writerow(["Kategori", "ÃœrÃ¼n BaÅŸlÄ±ÄŸÄ±", "Fiyat", "Min. SipariÅŸ", "Link"])
            writer.writerows(all_final_data)

        duration = time.time() - start_time
        print(f"\nğŸ‰ ALIBABA SCRAPER TAMAMLANDI!")
        print(f"â±ï¸  SÃ¼re: {int(duration)} saniye")
        print(f"ğŸ“Š Toplam Veri: {len(all_final_data)}")
        print(f"ğŸ’¾ Dosya: {file_path}")
        
    except Exception as e:
        print(f"âŒ Dosya kaydetme hatasÄ±: {e}")